---
title: "Aaron Swartz and AI"
date: 2026-02-12
draft: false
---

At the moment I was writing my first "Hello World" message, I still hadn't finished the film about Aaron Swartz. 
By the end of the film, I couldn't stop myself from crying. Hard and long enough to fall asleep sad. 
I mourn the person as much as what we lost as human beings that day.

Aaron wasn't just a genius in the field, in his field, the internet, computer science. He was a catalyst for change. The excuse "we're going to make an example of him" is too superficial for me. What the elites feared was much deeper. What they feared were the thousands of possibilities that his existence made possible.

And that is exactly what we all lost. Those billions of alternative timelines where Aaron is among us, revolutionizing AI. Because he has the skills and the support for it. And at the same time, ruining those super-corps that are profiting en masse from this new technology to turn it into a giant black box for the masses.

Even as we speak, these corps are trying to put spokes in the wheels to seize a monopoly on LLMs and push aside, legislate, and hinder the progress of open-source models like OLLAMA or Mistral. 
They put forward alarmist security arguments to scare governments, highlighting the possibility of carrying out "more effective" cyberattacks. The reality is that someone motivated enough doesn't need AI, and certainly not one with the restricted computing power of a local model. They could do it alone.

It doesn't suit Microsoft that you or I have access to a free AI, accessible wherever and whenever we want. They would prefer you to pay for Copilot, or ChatGPT, and that you access it only from their site to consult only what they allow you to consult. And nothing else.

In the end, this is also what Aaron fought against. What they want us to believe is similar to SOPA. 
Before, it was about legislating the internet and making it extremely restrictive to protect against hackers. 
Today, they create new antagonists to further chain AI with a leash that only they will hold. 
They simply want the monopoly on a new technology, to gatekeep it behind paywalls that you pay every month, while decreasing the quotas they offer to their users over time.

Just last month, with the release of recent Gemini models, Google decreased the request quota for Gemini Pro (their most powerful model for code, which therefore requires more tokens, the fuel of current AIs) for its users by giving them a ridiculous quota of 100 requests. All it really takes is a slightly prolonged discussion to be stopped dead. 
I find it ultra-frustrating. (I benefit from the free student subscription so I can use it. But I don't like it. So I started a project to popularize AI although there are certainly projects already doing it very well.)

In comparison, before the start of this year, the request limit was based on speed, so as long as the user didn't exceed a certain number of requests per hour, they weren't penalized. 
To give you an idea, if the limit was 50, which seems reasonable to me, you could do 50 during the first hour, 50 during the second hour, 50 during the third, and you've already exceeded the threshold they just set.

But the common man doesn't consume 50 requests per hour. It's a lie; they simply want to turn off the tap little by little after managing to make everyone taste what they are capable of offering. 
Besides, if you don't go check these things for yourself, they won't be displayed anywhere. 
The service continues to function as if nothing happened. I find it revolting. So if you don't reach 100 requests, you will never know.

Anyway. The system is poorly made. I don't like to paint an alarmist portrait of current events. I don't follow them actively; I consider it too resource-consuming for someone still in training. It becomes obsessive for me, so I try to keep my distance, but when it touches my daily life, I quickly make connections between the things I hear.

Furthermore, lately, we've seen a rise in the price of computer hardware, particularly System RAM and especially GPU VRAM. Manufacturers like NVIDIA prefer to produce for AI hosting providers because it's more lucrative, rather than selling to individuals.

What are the consequences? To run your local AI, you need memory. The more you have (VRAM), the more you can simulate a powerful AI. 
So what is happening is unhealthy. The hardware to have your own open-source AI is becoming increasingly inaccessible. At the same time, corporations are fighting against these same simulated AIs by trying to monopolize the field.

We must not let this happen. AI is the future. We must not let them take over this technology. Fortunately, resistance exists. We must democratize local AI, encourage initiatives like DeepSeek which is much more flexible towards the Open-Source community.

I am still thinking about the most effective ways to act. 
Writing on this blog doesn't really move things forward.

But it is also my way of paying tribute and liberating my thoughts.

Thank you for reading. 
Take care of yourselves.